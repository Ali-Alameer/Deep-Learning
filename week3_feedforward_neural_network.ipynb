{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-Alameer/Deep-Learning/blob/main/week3_feedforward_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkfgjYcE9R1z"
      },
      "source": [
        "In this code, we use the load_digits function from scikit-learn to load the digits dataset. Then, we split the data into training and test sets using train_test_split.\n",
        "\n",
        "We preprocess the data by dividing the pixel values by 16 to normalize them in the range of [0, 1]. We also convert the target labels to categorical format using to_categorical from Keras.\n",
        "\n",
        "Next, we create a simple feedforward neural network using Keras' Sequential model. The model consists of three dense layers with ReLU activation in the hidden layers and softmax activation in the output layer.\n",
        "\n",
        "We compile the model with the Adam optimizer, categorical cross-entropy loss function, and accuracy as the evaluation metric.\n",
        "\n",
        "Then, we train the model on the training data for 10 epochs with a batch size of 32. We also validate the model's performance on the test data during training.\n",
        "\n",
        "After training, we evaluate the model on the test data and print the test loss and accuracy.\n",
        "\n",
        "This code provides a basic example of how to implement a deep learning model using Keras for the digit dataset. You can experiment with different network architectures, hyperparameters, and evaluation metrics to further improve the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFM-1YGS87Xe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score\n",
        "\n",
        "# Load the digits dataset\n",
        "digits = load_digits()\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train / 16.0  # Normalize the pixel values to the range [0, 1]\n",
        "X_val = X_val / 16.0\n",
        "X_test = X_test / 16.0\n",
        "\n",
        "# Convert the target labels to categorical format\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Create a simple feedforward neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(64,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9AaUD4J-3mP"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "y_test_labels = y_test.argmax(axis=1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test_labels, y_pred_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test_labels, y_pred_labels, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test_labels, y_pred_labels, average='weighted')\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test_labels, y_pred_labels, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP1mNT5U-xTR"
      },
      "outputs": [],
      "source": [
        "# Plot the learning curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(np.arange(1, len(history.history['accuracy']) + 1), history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(np.arange(1, len(history.history['accuracy']) + 1), history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTeA9ky6BOm-"
      },
      "source": [
        "Let's have a look at our input dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtF1PW7V9nyQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Get the number of samples and image dimensions\n",
        "num_samples, img_height, img_width = X_train.shape[0], digits.images[0].shape[0], digits.images[0].shape[1]\n",
        "\n",
        "# Visualize the first few training images\n",
        "num_images_to_visualize = 5\n",
        "fig, axes = plt.subplots(1, num_images_to_visualize, figsize=(12, 4))\n",
        "\n",
        "for i in range(num_images_to_visualize):\n",
        "    axes[i].imshow(digits.images[i], cmap='gray')\n",
        "\n",
        "# Display image size and shape information\n",
        "print(\"Number of training samples:\", num_samples)\n",
        "print(\"Image size: {} x {}\".format(img_height, img_width))\n",
        "print(\"Image shape:\", digits.images[0].shape)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNjCcrVYCiOr"
      },
      "source": [
        "# Visualize the label distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOgNkidDBh-B"
      },
      "outputs": [],
      "source": [
        "label_counts = np.sum(y_train, axis=0)\n",
        "\n",
        "# Visualize the label distribution\n",
        "labels = range(10)\n",
        "plt.bar(labels, label_counts)\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Label Distribution\")\n",
        "plt.xticks(labels)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNnAbEsuJUkH9AJBR7JpgSZ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
