{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-Alameer/Deep-Learning/blob/main/week1_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keal_pZzqq-D"
      },
      "source": [
        "Let's build the Logistic Regression model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2r-kRaIj6Tp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Initialize parameters\n",
        "        num_samples, num_features = X.shape\n",
        "        self.weights = np.zeros(num_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Gradient descent optimization\n",
        "        for _ in range(self.num_iterations):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_predicted = self._sigmoid(linear_model)\n",
        "\n",
        "            # Calculate gradients\n",
        "            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / num_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            # Update parameters\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self._sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "        return y_predicted_cls\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfJqyp26k3I3"
      },
      "source": [
        "The LogisticRegression class is defined to encapsulate the functionality of the logistic regression model.\n",
        "\n",
        "The constructor (__init__) initializes the learning rate and the number of iterations for gradient descent. It also initializes the weights and bias as None.\n",
        "\n",
        "The fit method takes input features X and corresponding labels y as arguments and performs the training of the logistic regression model. It initialises the weights and bias, and then performs gradient descent for the specified number of iterations. The model's weights and bias are updated iteratively using the gradient of the loss function.\n",
        "\n",
        "The predict method takes input features X and returns the predicted labels using the learned weights and bias. It calculates the linear model by taking the dot product of the input features and the weights, adds the bias term, and applies the sigmoid function to obtain the predicted probabilities. The predicted probabilities are then converted to binary labels by using a threshold of 0.5.\n",
        "\n",
        "The _sigmoid method is a helper function that applies the sigmoid function element-wise to a given input.\n",
        "\n",
        "-- General info\n",
        "\n",
        "In Python, methods or functions that have an underscore _ in their name are often used to indicate that they are intended for internal or private use within a class or module.\n",
        "\n",
        "Also, a class is a blueprint or template that defines the properties (attributes) and behaviours (methods) of objects. It provides a way to create user-defined data types with their own characteristics and functionality.\n",
        "\n",
        "\n",
        "Furthermore, self is a conventionally used parameter name that refers to the instance of a class. It is a special variable that allows access to the attributes and methods of the class within its own methods. When defining methods within a class, the first parameter of the method is typically self, although you can choose any valid parameter name. The self parameter acts as a reference to the instance of the class.\n",
        "\n",
        "The __init__ method in Python is a special method, also known as the constructor. It is automatically called when an instance of a class is created. The primary purpose of the __init__ method is to initialize the attributes of the object with the values passed during the object's creation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGoBRaT2k5b2"
      },
      "source": [
        "You can create an instance of the LogisticRegression class and use it to train and predict on your dataset by following these steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygLnqcpMkn25"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the digits dataset\n",
        "digits = load_digits()\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create an instance of Logistic Regression\n",
        "model = LogisticRegression(learning_rate=0.0001, num_iterations=1000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Compute confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "# The results are not so good ! Think why !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdLIMbvHoOcm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the digit input data\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 4))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(digits.data[i].reshape(8, 8), cmap='binary')\n",
        "    ax.set_title(f\"Label: {digits.target[i]}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMgNhWPmgav2+LtOVrkHefH",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
